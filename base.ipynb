{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a6d152",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install cmake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9342c20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install opencv-python opencv_contrib-python\n",
    "%pip install face_recognition\n",
    "%pip install numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "038e1e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import os, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5a4418a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directory to store training images\n",
    "os.makedirs('training_faces', exist_ok=True)\n",
    "os.makedirs('encodings', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45ba41d",
   "metadata": {},
   "source": [
    "Save faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b298fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def capture_images():\n",
    "    #Name for the captured images\n",
    "    name = input(\"Enter name: \")\n",
    "\n",
    "    #Create a folder for person if it doesnt exist yet\n",
    "    person_folder = f\"training_faces/{name}\"\n",
    "    os.makedirs(person_folder, exist_ok= True)\n",
    "\n",
    "\n",
    "    #Initialize video capture\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    #Frames Loop\n",
    "    while True:\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            print(\"Failed to capture frame\")\n",
    "            break\n",
    "\n",
    "        cv2.imshow(\"Training - Press 'c' to capture, 'r' to restart or 'q' to quit\", frame)\n",
    "\n",
    "        #Capture the frame when 'c' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('c'):\n",
    "            img_path = f'training_faces/{name}/{name}_{len(os.listdir(person_folder))+1}.jpg'\n",
    "            cv2.imwrite(img_path, frame) #Save the original frame\n",
    "            print(f\"Image saved at: {img_path}\")\n",
    "\n",
    "        #Exit loop with when pressing 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        if cv2.waitKey(1) & 0xFF ==ord('r'):\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            return capture_images()\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "capture_images()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a3c22e",
   "metadata": {},
   "source": [
    "Encode and train based on faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10aacf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_save_encodings():\n",
    "    base_folder = \"training_faces\"\n",
    "    encoding_base = \"encodings\"\n",
    "    \n",
    "    os.makedirs(encoding_base, exist_ok=True)\n",
    "\n",
    "\n",
    "    for person_name in os.listdir(base_folder):\n",
    "        #Check if pictures of person exist\n",
    "        person_folder = os.path.join(base_folder, person_name)\n",
    "        if not os.path.isdir(person_folder):\n",
    "            continue\n",
    "\n",
    "        #Check if encodings folder for that person exist\n",
    "        person_encoding_folder = os.path.join(encoding_base, person_name)\n",
    "        os.makedirs(person_encoding_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "        #Exploere image files per person\n",
    "        for img_file in os.listdir(person_folder):\n",
    "            img_path = os.path.join(person_folder, img_file)\n",
    "            img = cv2.imread(img_path)\n",
    "            rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            face_locs = face_recognition.face_locations(rgb_img)\n",
    "\n",
    "            if len(face_locs) == 0:\n",
    "                print(f\"No face found in {img_file}, skipping.\")\n",
    "                continue\n",
    "\n",
    "            encoding = face_recognition.face_encodings(rgb_img, known_face_locations=face_locs)[0]\n",
    "            \n",
    "            #Save encoding separately\n",
    "            encoding_filename = os.path.splitext(img_file)[0] + \".npy\"\n",
    "            encoding_path = os.path.join(person_encoding_folder, encoding_filename)\n",
    "            np.save(encoding_path, encoding)\n",
    "            print(f\"Saved encoding: {encoding_path}\")\n",
    "\n",
    "def load_encodings():\n",
    "    encoding_base =\"encodings\"\n",
    "    encodings = []\n",
    "    names = []\n",
    "    \n",
    "    for person_name in os.listdir(encoding_base):\n",
    "        person_folder = os.path.join(encoding_base, person_name)\n",
    "        if not os.path.isdir(person_folder):\n",
    "            continue\n",
    "\n",
    "        for file in os.listdir(person_folder):\n",
    "            if file.endswith(\".npy\"):\n",
    "                encoding = np.load(os.path.join(person_folder, file))\n",
    "                encodings.append(encoding)\n",
    "                names.append(person_name)\n",
    "\n",
    "    return encodings, names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ee125d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_recognition():\n",
    "    known_encodings, known_names = load_encodings()\n",
    "    if len(known_encodings) == 0:\n",
    "        return\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    while True:\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "\n",
    "        #Convert to RGB\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        #Downscaling for better performance\n",
    "        scale_factor = 0.25\n",
    "        small_frame = cv2.resize(rgb_frame, (0,0), fx =  scale_factor, fy = scale_factor)\n",
    "        \n",
    "        \n",
    "        #Detect faces on the smaller frame\n",
    "        face_locations = face_recognition.face_locations(small_frame, model=\"hog\")\n",
    "        face_encs = face_recognition.face_encodings(small_frame, face_locations)\n",
    "\n",
    "        #Time to scale back\n",
    "        face_locations =[(int(top/scale_factor), int(right/scale_factor),\n",
    "                          int(bottom/scale_factor), int(left/scale_factor))\n",
    "                          for (top, right, bottom, left) in face_locations]\n",
    "        \n",
    "        for (top, right, bottom, left), face_enc in zip(face_locations, face_encs):\n",
    "            matches = face_recognition.compare_faces(known_encodings, face_enc, tolerance=0.5)\n",
    "            name = \"Unknown\"\n",
    "\n",
    "            if True in matches:\n",
    "                matched_idxs = [i for i, val in enumerate(matches) if val]\n",
    "                counts = {}\n",
    "                for idx in matched_idxs:\n",
    "                    counts[known_names[idx]] = counts.get(known_names[idx], 0) + 1\n",
    "                name = max(counts, key=counts.get)\n",
    "\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow(\"Real-Time Face Recognition\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d6a4d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved encoding: encodings\\JoseLuis\\JoseLuis_1.npy\n",
      "Saved encoding: encodings\\JoseLuis\\JoseLuis_2.npy\n",
      "Saved encoding: encodings\\JoseLuis\\JoseLuis_3.npy\n",
      "Saved encoding: encodings\\Kiara\\Kiara_1.npy\n",
      "Saved encoding: encodings\\Kiara\\Kiara_2.npy\n",
      "No face found in Kiara_3.jpg, skipping.\n",
      "Saved encoding: encodings\\Mafer\\Mafer_1.npy\n",
      "Saved encoding: encodings\\Mafer\\Mafer_2.npy\n",
      "Saved encoding: encodings\\Mafer\\Mafer_3.npy\n"
     ]
    }
   ],
   "source": [
    "process_and_save_encodings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9670230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_recognition()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
